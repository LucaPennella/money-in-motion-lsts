# Money in Motion: Micro-Velocity and Usage of Ethereum’s Liquid Staking Tokens

Reproducible code & data for the paper:

> **Money in Motion: Micro-Velocity and Usage of Ethereum’s Liquid Staking Tokens**  
> B. Kraner, L. Pennella, N. Vallarano, C. J. Tessone (2025)


To reproduce the result, you need a `.env` file. An example is provided in `env.example`.

# Configuration
First, create a python virtual environment where to install all the modules you need for the project.
You can do this by with conda:
```
conda create --name <env> --file requirements.txt
```
## install submodules
- clone the repo `ethereum-event-tracker` ([ethereum-event-tracker](https://gitlab.uzh.ch/bdlt/ethereum-event-tracker)), move in and and install it in editor mode:
    ```
    cd ethereum-event-tracker
    pip install -e .
    ```
- clone the repo `ethereum-variable-tracker` ([ethereum-variable-tracker](https://gitlab.uzh.ch/bdlt/ethereum-variable-tracker)), move in and install it in editor mode:
    ```
    cd ethereum-variable-tracker
    pip install -e .
    ```
- clone the repo [MicroVelocityAnalyzer](https://github.com/fdecollibus/MicroVelocityAnalyzer), branch `parallelised_plus_bilance`, the parallelised branch, move in and install in editor mode:
  ```
    cd MicroVelocityAnalyzer
    pip install -e .
  ```
# Run the Paper
## Data Collection
Collect Transfer and TransferShares events:
```
bash event_collection.sh
```
as output, `input/event` is populated of files, per each event on a 50k blocks range.

Collect `stETH/Lido.sol` variables state
- `BUFFERED_ETHER_POSITION`
- `BEACON_BALANCE_POSITION`
- `DEPOSITED_VALIDATORS_POSITION`
- `BEACON_VALIDATORS_POSITION`
- `TOTAL_SHARES_POSITION`
```
bash variable_collection.sh
```
- as output, `input/variables` is populated with files, per each variables once every 50k blocks.

Run the data preprocessing and MicroVelocity trough the bash script:
```
bash microvelocity.sh
```
- the preprocessing outputs
    - two csv to pass to `micro-velocity-analyzer`
        - `$PROCESSED/shares-allocated.csv`
        - `$PROCESSED/shares-transfers.csv`
    - two parquet files:
        - `$PROCESSED/stETH-TransferShares.parquet` contains all stETH Transfer in shares value
        - `$PROCESSED/lido-variables.parquet` contains per block the value of the collected varibles + total pooled eth and token to share conversion.
- `micro-velocity-analyzer` outputs a `pickle` file containing final balances and velocities every `N_BLOCKS=7200`.

Run the post-processing of the data generated by `microvelocity.sh` trough the script:
```
postprocess.sh
```
- postprocessing outputs:
      - dictionary containing:
          - `timestamp`
          - `blocknumber`
          - `PQ_total`
          - `V_[user class]` where user class represent the category of the user
          - `M_[user class]` where user class represent the category of the user
          - `MV_[user class]` where user class represent the category of the user

studied user categories are:
- 'Whale', # (>= 10k stETH)
- 'Orca',  # (3-10k)
- 'Dolphin', # (1-3k)
- 'Fish', # (100-1000)
- 'Shrimp', # (10-100)
- 'Krill', # (1-10)
- 'Plankton', # (<1)
- 'high', # >= 100 stETH (from Whale to Fish)
- 'low',  # < 100 stETH (from Shrimp to Plankton)
- 'total' # all
